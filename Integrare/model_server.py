from flask import Flask, request, jsonify
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from peft import PeftModel
from load_faiss import get_vector_store, find_relevant_urls

print("ğŸ”§ IniÈ›ializare server model...")

# IncarcÄƒ modelul TinyLLaMA + adapter PEFT
base_model_id = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
adapter_path = "D:/chatbot/adapter"

print("ğŸ”„ ÃncÄƒrcare model È™i tokenizer...")
tokenizer = AutoTokenizer.from_pretrained(base_model_id)
base_model = AutoModelForCausalLM.from_pretrained(base_model_id).to("cuda")
model = PeftModel.from_pretrained(base_model, adapter_path).merge_and_unload().to("cuda")
pipe = pipeline("text-generation", model=model, tokenizer=tokenizer, device=0, max_new_tokens=256)

print("âœ… Model Ã®ncÄƒrcat È™i pregÄƒtit.")

# ÃncarcÄƒ FAISS vector store o singurÄƒ datÄƒ
print("ğŸ” Construim vector store FAISS...")
vector_store = get_vector_store()
if not vector_store:
    raise RuntimeError("âŒ Nu s-au putut Ã®ncÄƒrca documentele Ã®n FAISS.")

print("âœ… Vector store creat.")

# Flask app pentru primire Ã®ntrebÄƒri
app = Flask(__name__)

@app.route("/generate", methods=["POST"])
def generate():
    data = request.get_json()
    question = data.get("prompt", "")

    if not question.strip():
        return jsonify({"error": "Promptul este gol."}), 400

    # CÄƒutare Ã®n vector store
    try:
        relevant_docs = vector_store.similarity_search(question, k=3)
        context = "\n".join([doc.page_content for doc in relevant_docs])
    except Exception as e:
        return jsonify({"error": f"Eroare la cÄƒutare: {e}"}), 500

    if not context.strip():
        return jsonify({"answer": "â— Nu am gÄƒsit informaÈ›ii relevante Ã®n documente."})

    # GenereazÄƒ rÄƒspuns
    prompt = f"<|user|>\nContext:\n{context}\n\nÃntrebare: {question}\nTe rog sÄƒ rÄƒspunzi Ã®n limba romÃ¢nÄƒ.\n<|assistant|>"
    try:
        output = pipe(prompt)[0]['generated_text'].replace(prompt, '').strip()
    except Exception as e:
        return jsonify({"error": f"Eroare la generare: {e}"}), 500

    # CautÄƒ linkuri utile
    urls = find_relevant_urls(question, context)
    if urls:
        output += "\n\nğŸ“ Linkuri utile:"
        for url in urls[:3]:
            output += f"\nâ€¢ {url}"

    return jsonify({"answer": output})


if __name__ == "__main__":
    app.run(port=5001)
